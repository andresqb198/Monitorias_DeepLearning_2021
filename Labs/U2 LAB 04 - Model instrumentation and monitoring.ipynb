{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2.4 - Model instrumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://rramosp.github.io/2021.deeplearning/intro.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cO5EcNXSUH-B"
   },
   "source": [
    "### LAB SUMMARY\n",
    "\n",
    "\n",
    "In this lab you will be implementing Tensorflow Callbacks that will be invoked at different stages when a model gets trained.\n",
    "\n",
    "Read carefully the following tutorial: [https://www.tensorflow.org/guide/keras/custom_callback](https://www.tensorflow.org/guide/keras/custom_callback)\n",
    "\n",
    "\n",
    "### load sample MNIST data as customary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SW5RDD8qUH-C",
    "outputId": "eaa3d9ec-5f41-495b-88a7-a9eb8caeba41"
   },
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"local/data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values #Se carga el dataset MNIST de forma local\n",
    "X=mnist[:,1:785]/255.               #Se normalizan los datos\n",
    "y=mnist[:,0]\n",
    "print(\"dimension de las imagenes y las clases\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2iXzcb0jUH-E",
    "outputId": "8a16a944-05df-4549-82b2-95d0de7805d9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)   #Se hace train-test-split con \n",
    "X_train = X_train.astype(np.float32)         #Se cambia el tipo de representacion binaria de los datos\n",
    "X_test  = X_test.astype(np.float32)\n",
    "y_train_oh = np.eye(10)[y_train]          #Se realiza one hot encoding\n",
    "y_test_oh  = np.eye(10)[y_test]\n",
    "print(X_train.shape, y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HmoxgIGkUH-G"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xTl-dXJ9UH-J"
   },
   "source": [
    "### A basic multi layered dense model\n",
    "\n",
    "observe that the function allows us to parametrize the number of hidden layers and their activation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5wi-OteUH-K"
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim=784, output_dim=10, num_hidden_layers=6, hidden_size=10, activation=\"relu\"):\n",
    "\n",
    "    model = Sequential()     #Se crea un modelo instancia de la clase Sequential\n",
    "    model.add(Dense(hidden_size, activation=activation, input_dim=input_dim, name=\"Layer_%02d_Input\"%(0)))  #Se agrega la capa de entrada\n",
    "    \n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(Dense(hidden_size, activation=activation, name=\"Layer_%02d_Hidden\"%(i+1)))     #Se agregan las capas ocultas\n",
    "   \n",
    "    model.add(Dense(output_dim, activation=\"softmax\", name=\"Layer_%02d_Output\"%(num_hidden_layers+1)))   #Se agrega la capa de salida\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])   #Se configura el optimizador y la funcion de costo\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdjyzRhkUH-N"
   },
   "source": [
    "## TASK 1: Weights monitoring callback\n",
    "\n",
    "Create a callback that:\n",
    "\n",
    "- when each epoch ends, retrieves the weights of the layer with name `self.layer_name`.\n",
    "- gets is kernels weights.\n",
    "- computes the mean and standard deviation of those weights.\n",
    "- appends them to `self.mean_per_epoch` and `self.std_per_epoch`\n",
    "\n",
    "When used with a model, at the end of any training it will contain a list of weights means and another list of weights stds, both with one element per each epoch. With this we can monitor how the weights in a specific layer progress over the training process. Tensorboard offers a similar functionality, but the goal with this task is to get acquainted with the callback mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LayerWeightsCallback(layer_name):\n",
    "    class LayerWeightsCallback_class(Callback):   #Se crea la clase correspondiente a los CallBack de los pesos de la capa\n",
    "\n",
    "        def __init__(self, layer_name):   #Metodo constructor de la clase\n",
    "            super().__init__()             #Linea para manejar las multiples herencias (Concepto de POO)\n",
    "            self.mean_per_epoch = []      #Lista donde se almacenan los promedios de los pesos por cada epoca\n",
    "            self.std_per_epoch = []       #Lista donde se almacenan las desviaciones estandar de los pesos por cada epoca\n",
    "            self.layer_name = layer_name  #Nombre de la capa\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "           #Your code start here \n",
    "            w = ... # get the weights from layer_name in self.model\n",
    "            ... # append to self.mean_per_epoch the weights mean \n",
    "            ... # append to self.std_per_epoch the weights std  \n",
    "            #Your code ends here\n",
    "    \n",
    "    return LayerWeightsCallback_class(layer_name)    #Retorna la instancia correspondiente al nombre de la capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually test your code with the following cell. Your callback should report the weights mean and std doubling at every epoch, just with the same values as they are being computed within the for loop. The loop simulates training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(input_dim=2, output_dim=3, num_hidden_layers=1, hidden_size=2, activation=\"sigmoid\")  #Crea el modelo\n",
    "layer_names = [i.name for i in model.layers if not \"Input\" in i.name]      #Crea lista con los nombres de la capa\n",
    "layer = model.get_layer(np.random.choice(layer_names))          #Obtiene cualquier capa de forma aleatoria\n",
    "\n",
    "cb = LayerWeightsCallback(layer.name)   #Crea una instancia de la clase LayerWeightsCallback_class\n",
    "cb.model = model         #Agrega el modelo creado a la instancia del CallBack\n",
    "\n",
    "m, s, wh = [], [], []\n",
    "for epoch in range(3):         #Para cada epoca\n",
    "    w = layer.get_weights()[0]     #Se obtienen los pesos\n",
    "    wh.append(w)                   #Se agregan los pesos en la lista wh\n",
    "    print (\"epoch\", epoch, \"weights mean/std\", np.mean(w),np.std(w))\n",
    "    cb.on_epoch_end(epoch)          #Se realiza el Callback\n",
    "    layer.set_weights([i*2 for i in layer.get_weights()])    \n",
    "    \n",
    "print (\"\\nweight mean at each epoch\", cb.mean_per_epoch) #Resultado del callback\n",
    "print (\"weight std  at each epoch\", cb.std_per_epoch)    #Resultado del callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use your class to keep track of weights while training. We choose to keep track of weights with your callback for all the layers. \n",
    "\n",
    "Observe how we plot the weights progress with the data gathered by your callback. What interpretation can you give to the plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IRua6cxAUH-N",
    "outputId": "6af87062-3947-46a5-c78f-c50627fb7c1e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model(num_hidden_layers=3, activation=\"sigmoid\")      #Se crea el modelo\n",
    "cbs = [LayerWeightsCallback(i.name) for i in model.layers]        #Se crea una lista donde se almacenan los callbacks\n",
    "model.fit(X_train, y_train_oh, epochs=100, batch_size=8, \n",
    "          validation_data=(X_test, y_test_oh), callbacks=cbs)        #Se entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_epochs(cbset, title=\"\"):\n",
    "    cm = plt.cm.Blues\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.subplot(121)\n",
    "    for i,cb in enumerate(cbset):\n",
    "        plt.plot(cb.mean_per_epoch, label=cb.layer_name, color=cm(int(255*(i+1)/(len(cbset)))))\n",
    "        plt.xlabel(\"epochs\"); plt.grid(); plt.title(title+\" mean\")\n",
    "    plt.subplot(122)\n",
    "    for i,cb in enumerate(cbset):\n",
    "        plt.plot(cb.std_per_epoch, label=cb.layer_name, color=cm(int(255*(i+1)/(len(cbset)))))\n",
    "        plt.xlabel(\"epochs\"); plt.grid(); plt.title(title+\" std\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "plot_epochs(cbs, \"WEIGHTS\")   #Se dibujan los callbacks obtenidos durante el entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Activations monitoring callback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observe how, given a model and a certain input, we can get the activations at different layers in a very straight forward manner. If we do this before training (`.fit`) it is also ok, the model will simply use the initial random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(num_hidden_layers=3, activation=\"sigmoid\")     #Se crea el modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_layer_0 = model.layers[0](X_train)           #Se obtienen las activaciones de la capa 0\n",
    "activations_layer_1 = model.layers[1](activations_layer_0) #Se obtienen las activaciones de la capa 1\n",
    "activations_layer_0.shape, activations_layer_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a callback that:\n",
    "\n",
    "- when each epoch ends, feeds `self.X` into the model and retrieves the activations at the output of layer with name `self.layer_name`.\n",
    "- computes the mean and standard deviation of those activations.\n",
    "- appends them to `self.mean_per_epoch` and `self.std_per_epoch`\n",
    "\n",
    "When used with a model, at the end of any training it will contain a list of activations means and another list of activation stds, both with one element per each epoch. With this we can monitor how the activation in a specific layer progress over the training process. Tensorboard offers a similar functionality, but the goal with this task is to get acquainted with the callback mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainValActivationsCallback(layer_name, X):\n",
    "    class TrainValActivationsCallback_class(Callback):  #Clase TrainValActivationsCallback_class para el Callback\n",
    "\n",
    "        def __init__(self, layer_name, X):  #Metodo constructor\n",
    "            super().__init__()       #Linea para manejar las multiples herencias (Concepto de POO)\n",
    "            self.mean_per_epoch = []  #Lista para almacenar el promedio de activaciones por epoca\n",
    "            self.std_per_epoch = []   #Lista para almacenar las desviaciones estandar de las activaciones por epoca\n",
    "            self.layer_name = layer_name     #Nombre de la capa\n",
    "            self.X = X                    #X (Entrada)\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            #Your code starts here\n",
    "            a = ... # feed self.X into self.model and get the activations at layer_name\n",
    "               .... # append to self.mean_per_epoch the activations mean \n",
    "            .... # append to self.std_per_epoch the activations std \n",
    "            \n",
    "            #Your code Ends here\n",
    "    \n",
    "    return TrainValActivationsCallback_class(layer_name, X)   #Devuelve una instancia de la clase TrainValActivationsCallback_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test your code with the following cell. Observe that\n",
    "\n",
    "- we create a small input dataset and model\n",
    "- invoke your callback implementation\n",
    "- your callback must contain two lists: `mean_per_epoch` and `std_per_epoch` with one single value each\n",
    "- you can check that single value with our computation. We do this computation in two different ways (1) by using explicitly the model layers; and (2) by using matrix multiplication with layers weights (`linear activation`== `no activation`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in = np.random.random(size=(5,2)).astype(np.float32)\n",
    "print (\"input data\\n\", X_in)\n",
    "model = get_model(input_dim=2, output_dim=3, num_hidden_layers=2, hidden_size=2, activation=\"linear\") #Se crea el modelo\n",
    "layer_name = 'Layer_02_Hidden'    #El nombre por defecto de la capa\n",
    "layer = model.get_layer(layer_name) #Se obtiene la capa respectiva al nombre\n",
    "\n",
    "cb = TrainValActivationsCallback(layer.name, X_in)   #Se obtiene la instancia del callback\n",
    "cb.model = model          #Se le agrega el modelo creado\n",
    "cb.on_epoch_end(epoch)    #Llamada al metodo on_epoch_end() del callback\n",
    "    \n",
    "print (\"\\nactivations at\", layer_name)\n",
    "print (\"\\nactivation mean/std with your callback\", cb.mean_per_epoch, cb.std_per_epoch)\n",
    "\n",
    "l0,l1,l2,l3 = model.layers\n",
    "a = l2(l1(l0(X_in))).numpy() \n",
    "print (\"using model layer functions            \", a.mean(), a.std())\n",
    "\n",
    "a = X_in.dot(l0.get_weights()[0]).dot(l1.get_weights()[0]).dot(l2.get_weights()[0])\n",
    "print (\"manual matrix mult linear activation   \", a.mean(), a.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use your class to keep track of activations while training. We choose to keep track of activations with your callback for all the layers. \n",
    "\n",
    "Observe how we plot the activations progress with the data gathered by your callback. What interpretation can you give to the plots?\n",
    "\n",
    "In this case, we are creating a callback for each layer for train and for test data. If activations are similar in both train and test it may mean that the train/test splits are being treated similarly by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(num_hidden_layers=3, activation=\"sigmoid\")      #Se crea el modelo\n",
    "cbs_train = [TrainValActivationsCallback(i.name, X_train) for i in model.layers]       #Se obtienen los callbacks del entrenamiento\n",
    "cbs_test  = [TrainValActivationsCallback(i.name, X_test) for i in model.layers]    #Se obtienen los callbacks de la validacion\n",
    "model.fit(X_train, y_train_oh, epochs=100, batch_size=32, \n",
    "          validation_data=(X_test, y_test_oh), callbacks=cbs_train+cbs_test)       #Se entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_epochs(cbs_train, \"ACTIVATIONS TRAIN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_epochs(cbs_test, \"ACTIVATIONS TEST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
