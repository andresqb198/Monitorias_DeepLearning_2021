{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2.3 - Pairwise classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://rramosp.github.io/2021.deeplearning/intro.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB SUMMARY\n",
    "\n",
    "In this lab we will use define a **slightly different** machine learning task. Given two MNIST images **as input** we want a network with a binary output: `1` if both images belong to the same MNIST class, and `0` otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"local/data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values   #Se carga el dataset MNIST de forma local\n",
    "X=(mnist[:,1:785]/255.).astype(np.float32)   #Se normalizan los datos\n",
    "y=(mnist[:,0]).astype(int)\n",
    "print(\"dimension de las imagenes y las clases\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xts, ytr, yts = train_test_split(X,y, test_size=0.3)          #Se realiza el train-test split con 30% para validacion\n",
    "Xtr.shape, ytr.shape, Xts.shape, yts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIRST**, observe how we build a labelled dataset for this task, so that each training example has:\n",
    "\n",
    "- two images selected randomly from the original dataset\n",
    "- label `0` if they belong to the same class, or `1` otherwise\n",
    "\n",
    "This way, the resulting data structures\n",
    "\n",
    "- `pXtr` and `pXts` contain the paired images, for train and for test\n",
    "- `pytr` and `pyts` contain the labels of the corresponding paired images, for train and for test\n",
    "- `eytr` and `eyts` contain the `0`/`1` new labels, one for each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairup(X, y, n_pairs_per_class, same_class):\n",
    "    \n",
    "    idxs = None\n",
    "    labels = np.unique(y)     #Cantidad de clases que hay\n",
    "    for i in labels:            #Para cada clase que exista\n",
    "        idxs_p1 = np.argwhere(y==i)[:,0] if same_class else np.argwhere(y!=i)[:,0]     #Configura los indices correspondientes por clase\n",
    "        idxs_p2 = np.argwhere(y==i)[:,0]\n",
    "        #Organiza en forma de stack los indices\n",
    "        c = np.vstack([\n",
    "                    np.random.choice(idxs_p1, size=n_pairs_per_class, replace=True),\n",
    "                    np.random.choice(idxs_p2, size=n_pairs_per_class, replace=True)\n",
    "            ]).T\n",
    "        \n",
    "        idxs = c if idxs is None else np.vstack((idxs,c))  \n",
    "        \n",
    "    X_pairs = [X[idxs[:,0]],X[idxs[:,1]]]\n",
    "    y_pairs = [y[idxs[:,0]],y[idxs[:,1]]]\n",
    "    y_labels = y[idxs[:,0]]==y[idxs[:,1]]        \n",
    "    \n",
    "    return idxs, X_pairs, y_pairs, y_labels\n",
    "\n",
    "def build_image_pairs(X,y,n_pairs_per_class):\n",
    "    idxs0, pX0, py0, ey0 = pairup(X, y, n_pairs_per_class, same_class=False) \n",
    "    idxs1, pX1, py1, ey1 = pairup(X, y, n_pairs_per_class, same_class=True)\n",
    "    \n",
    "    pX = [np.vstack((i,j)) for i,j in zip(pX0, pX1)]\n",
    "    py = [np.hstack((i,j)) for i,j in zip(py0, py1)]\n",
    "    ey = np.hstack((ey0, ey1))\n",
    "    idxs = np.vstack((idxs0, idxs1))\n",
    "    \n",
    "    return idxs, pX, py, ey.astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr, pXtr, pytr, eytr = build_image_pairs(Xtr, ytr, n_pairs_per_class=100)\n",
    "its, pXts, pyts, eyts = build_image_pairs(Xts, yts, n_pairs_per_class=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "understand and inspect the structures created and observe how the function above creates a **balanced** dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[i.shape for i in pXtr], [i.shape for i in pytr], itr.shape, eytr.shape    #Dimensiones del conjunto de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[i.shape for i in pXts], [i.shape for i in pyts], its.shape, eyts.shape   #Dimensiones del conjunto de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (\"class distribution %.2f::%.2f\"%(np.mean(eytr), 1-np.mean(eytr)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dibuja un par de imagenes aleatorio con su respectiva etiqueta\n",
    "for _ in range(5):\n",
    "    i = np.random.randint(len(pXtr[0]))\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(pXtr[0][i].reshape(28,28), cmap=plt.cm.Greys_r); \n",
    "    plt.ylabel(\"CLASS %d\"%(eytr[i]));\n",
    "    plt.title(\"pair_0 :     %d\"%(pytr[0][i])); plt.xticks([],[]); plt.yticks([],[])\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(pXtr[1][i].reshape(28,28), plt.cm.Greys_r); \n",
    "    plt.title(\"pair_1 :     %d\"%pytr[1][i]); plt.xticks([],[]); plt.yticks([],[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: Multi-input model\n",
    "\n",
    "Create a model with the architecture depicted in the following figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='local/imgs/twoinputs.png', width=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that \n",
    "\n",
    "- it will have **TWO** input layers with `input_dim=784` neurons each.\n",
    "- there is ony **ONE** output neuron.\n",
    "- the model summary should be as follows and **MUST NAME THE LAYERS ACCORDINGLY** (but not the `tf.concat` which is just an operation, not a layer):\n",
    "\n",
    "<pre>\n",
    "\n",
    "    __________________________________________________________________________________________________\n",
    "    Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "    ==================================================================================================\n",
    "    input_img0 (InputLayer)         [(None, 784)]        0                                            \n",
    "    __________________________________________________________________________________________________\n",
    "    input_img1 (InputLayer)         [(None, 784)]        0                                            \n",
    "    __________________________________________________________________________________________________\n",
    "    layer1_img0 (Dense)             (None, 100)          78500       input_img0[0][0]                 \n",
    "    __________________________________________________________________________________________________\n",
    "    layer1_img1 (Dense)             (None, 100)          78500       input_img1[0][0]                 \n",
    "    __________________________________________________________________________________________________\n",
    "    tf_op_layer_concat_39 (TensorFl [(None, 200)]        0           layer1_img0[0][0]                \n",
    "                                                                     layer1_img1[0][0]                \n",
    "    __________________________________________________________________________________________________\n",
    "    layer2_common (Dense)           (None, 100)          20100       tf_op_layer_concat_39[0][0]      \n",
    "    __________________________________________________________________________________________________\n",
    "    output (Dense)                  (None, 1)            101         layer2_common[0][0]              \n",
    "    ==================================================================================================\n",
    "    Total params: 177,201\n",
    "    Trainable params: 177,201\n",
    "    Non-trainable params: 0\n",
    "    __________________________________________________________________________________________________\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim):\n",
    "    \n",
    "    inputs1  = tf.keras.layers.Input(shape=input_dim, name=\"input_img0\")    #Capa de entrada 1\n",
    "    inputs2  = tf.keras.layers.Input(shape=input_dim, name=\"input_img1\")    #Capa de entrada 2\n",
    "    #Your code starts here\n",
    "         ...\n",
    "    #Your code ends here\n",
    "    model = tf.keras.Model(inputs=[inputs1, inputs2], outputs=outputs)  #Creacion del modelo  \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')   #Configuracion del modelo con el optimizador y la funcion de perdida\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(X.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test your model**\n",
    "\n",
    "now we can test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(X.shape[1])       #Creacion del modelo\n",
    "model.fit(pXtr, eytr, batch_size=16, epochs=20) #Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ts = (model.predict(pXts)[:,0]>.5).astype(int)    #Predicciones conjunto de validacion\n",
    "preds_tr = (model.predict(pXtr)[:,0]>.5).astype(int)    #Predicciones conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"accuracy in train data %.2f\"%(np.mean(preds_tr==eytr)))\n",
    "print (\"accuracy in test data  %.2f\"%(np.mean(preds_ts==eyts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspect TEST predictions. Do you see any class getting more confused with others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    i = np.random.randint(len(pXts[0]))\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(pXts[0][i].reshape(28,28), cmap=plt.cm.Greys_r)\n",
    "    plt.ylabel(\"PREDICTION %d\\nTARGET %d\"%(preds_ts[i], eyts[i]))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(pXts[1][i].reshape(28,28), cmap=plt.cm.Greys_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Measure per-class accuracy\n",
    "\n",
    "For each class we want to measure what is the prediction accuracy for the binary task when it participates in a pair. Observe how we gather the labels of each pair together with the binary prediction and the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts = pd.DataFrame(np.vstack((pyts[0],pyts[1], eyts, preds_ts)).T, columns=[\"pair_0\", \"pair_1\", \"true\", \"pred\"])\n",
    "ts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "of course, the `true` value coincides with `pair_0` being equal or different from `pair_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.mean((ts.pair_0==ts.pair_1)==ts.true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute, per-class accuracy in this task, for instance for class 2:\n",
    "\n",
    "- select the rows where `pair_0` or `pair_1` is 2\n",
    "- measure the percentage of time in the selected rows where `true==pred`\n",
    "\n",
    "for instance, for the following DataFrame\n",
    "\n",
    "            pair_0  pair_1  true  pred\n",
    "        0        0       0     1     1\n",
    "        1        0       0     1     1\n",
    "        2        0       0     1     1\n",
    "        3        2       2     1     1\n",
    "        4        1       1     1     1\n",
    "        5        0       2     0     0\n",
    "        6        2       2     1     0\n",
    "        7        2       2     1     1\n",
    "        8        2       2     1     1\n",
    "        9        1       1     1     1\n",
    "        10       1       1     1     1\n",
    "        11       1       1     1     1\n",
    "        12       2       2     1     1\n",
    "        13       0       2     0     1\n",
    "        14       2       2     1     1\n",
    "        15       0       0     1     1\n",
    "        16       2       2     1     1\n",
    "        17       1       1     1     0\n",
    "        18       1       1     1     1\n",
    "        19       1       1     1     1\n",
    "        \n",
    "you must return this accuracies:\n",
    "\n",
    "        {0: 0.8333333333333334, 1: 0.8571428571428571, 2: 0.7777777777777778}\n",
    "\n",
    "\n",
    "the accuracies must be returned as a dictionary such as above. They keys are the original class labels, and the values the accuracy just described.\n",
    "\n",
    "The accuracies must be correct up to 3 decimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perclass_bin_accuracy(ts):\n",
    "        \n",
    "    r = {}\n",
    "    for i in np.unique(ts.pair_0.tolist() + ts.pair_1.tolist()):\n",
    "        #Your code starts here\n",
    "        ...\n",
    "        \n",
    "        r[i] = ... # your code here\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test your code with the example above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(\n",
    "        np.array([[0, 0, 1, 1],[0, 0, 1, 1],[0, 0, 1, 1],[2, 2, 1, 1],[1, 1, 1, 1],\n",
    "                  [0, 2, 0, 0],[2, 2, 1, 0],[2, 2, 1, 1],[2, 2, 1, 1],[1, 1, 1, 1],[1, 1, 1, 1],[1, 1, 1, 1],\n",
    "                  [2, 2, 1, 1],[0, 2, 0, 1],[2, 2, 1, 1],[0, 0, 1, 1],[2, 2, 1, 1],[1, 1, 1, 0],[1, 1, 1, 1],\n",
    "                  [1, 1, 1, 1]]), \n",
    "    columns=[\"pair_0\", \"pair_1\", \"true\", \"pred\"])\n",
    "perclass_bin_accuracy(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test your code with other random examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, n_classes = 20, 3\n",
    "p0 = np.random.randint(n_classes, size=n)\n",
    "p1 = np.random.randint(n_classes, size=n)\n",
    "dtrue = (p0==p1).astype(int)\n",
    "preds = np.random.randint(2, size=n)\n",
    "td = pd.DataFrame([p0,p1,dtrue,preds], index=[\"pair_0\", \"pair_1\", \"true\", \"pred\"]).T\n",
    "\n",
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perclass_bin_accuracy(td)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
